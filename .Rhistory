destfile = "R-examples/HoustonENAR2012final.shx")
# Now read all the files into a single data frame
wacounty <- rgdal::readOGR(dsn="R-examples",layer="HoustonENAR2012final")
class(wacounty)
##Map the tracts using plot...old school
# Here are the outlines
plot(houston)
##Load libraries
library(maptools)     # loads sp library too
library(RColorBrewer) # creates nice color schemes
library(classInt)     # finds class intervals for continuous variables
library(spgwr)        # Adds the geographically weighted regression functions
library(rgdal)        # Provides tool for reading in shapefiles
# Set my working directory (Lance's here for example)
#setwd("~/Desktop/")
##Read in shapefile - Houston Census Tracts
#houston = readOGR(dsn = getwd() ,layer = "HoustonENAR2012final")
# Create directory
if (!("R-examples" %in% list.files())) {
dir.create("R-examples")
}
# Download files using urls
# If this throws an error, comment out and manually download the .shp,
# .shx and .dbf files from the website.
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/HoustonENAR2012final.dbf",
destfile = "R-examples/HoustonENAR2012final.dbf")
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/HoustonENAR2012final.shp",
destfile = "R-examples/HoustonENAR2012final.shp")
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/HoustonENAR2012final.shx",
destfile = "R-examples/HoustonENAR2012final.shx")
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/HoustonENAR2012final.sbn",
destfile = "R-examples/HoustonENAR2012final.sbn")
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/HoustonENAR2012final.sbx",
destfile = "R-examples/HoustonENAR2012final.sbx")
# Now read all the files into a single data frame
houston<- rgdal::readOGR(dsn="R-examples",layer="HoustonENAR2012final")
class(houston)
##Map the tracts using plot...old school
# Here are the outlines
plot(houston)
## Making choropleth maps
# Define the variable (attribute) to shade tracts by
pop2000 <- houston@data$POP2000
# Define the number of classes
nclr <- 5  # quintiles
# Use RColorBrewer to choose the colors
plotclr <- brewer.pal(nclr,"BuPu")
class <- classIntervals(pop2000, nclr, style="quantile")
colcode <- findColours(class, plotclr)
#Fill in the tracts with the colors
plot(houston, col=colcode, add=T)
#Add a title
title(main="Population 2000",
sub="Quantile (Equal-Frequency) Class Intervals")
#Add a legend  (Coordinates are in longitude, latitude).
legend(-95.7, 29.65, legend=names(attr(colcode, "table")),
fill=attr(colcode, "palette"), cex=0.6, bty="n")
# The data table has a lot of census data and various transformations
# of the violent crime, alcohol sales, and drug arrest data.  The next
# section pulls the values we want.
# Outcome:  Number of violent crimes by tract
violence = houston@data$violence_2
# Divide by the 2000 population to get the rate
violence.rate = violence/houston@data$tot_pop
# Covariate 1 (log standardized total alcohol sales)
Z.log.total = houston@data$Zl_total
# Covariate 2 (log standardized illegal drug arrests)
Z.log.drug = houston@data$Zl_drug
# set up maps 2 rows of 2 plots each.
#par(mfrow=c(2,2))
# Plot Outcome first
plot(houston)
# Define the number of classes
nclr <- 5  # quintiles
# Use RColorBrewer to choose the colors
plotclr <- brewer.pal(nclr,"BuPu")
class <- classIntervals(violence.rate, nclr, style="quantile")
colcode <- findColours(class, plotclr)
#Fill in the tracts with the colors
plot(houston, col=colcode, add=T)
#Add a title
title(main="Violence Rate",
sub="Quantile (Equal-Frequency) Class Intervals")
#Add a legend  (Coordinates are in longitude, latitude).
legend(-95.7, 29.65, legend=names(attr(colcode, "table")),
fill=attr(colcode, "palette"), cex=0.6, bty="n")
# Next plot stdized log total alcohol sales
plot(houston)
# Define the number of classes
nclr <- 5  # quintiles
# Use RColorBrewer to choose the colors
plotclr <- brewer.pal(nclr,"BuPu")
class <- classIntervals(Z.log.total, nclr, style="quantile")
colcode <- findColours(class, plotclr)
#Fill in the tracts with the colors
plot(houston, col=colcode, add=T)
#Add a title
title(main="Std log total sales",
sub="Quantile (Equal-Frequency) Class Intervals")
#Add a legend  (Coordinates are in longitude, latitude).
legend(-95.7, 29.65, legend=names(attr(colcode, "table")),
fill=attr(colcode, "palette"), cex=0.6, bty="n")
# Next plot stdized log illegal arrests
plot(houston)
# Define the number of classes
nclr <- 5  # quintiles
# Use RColorBrewer to choose the colors
plotclr <- brewer.pal(nclr,"BuPu")
class <- classIntervals(Z.log.drug, nclr, style="quantile")
colcode <- findColours(class, plotclr)
#Fill in the tracts with the colors
plot(houston, col=colcode, add=T)
#Add a title
title(main="Std log drug arrests",
sub="Quantile (Equal-Frequency) Class Intervals")
#Add a legend  (Coordinates are in longitude, latitude).
legend(-95.7, 29.65, legend=names(attr(colcode, "table")),
fill=attr(colcode, "palette"), cex=0.6, bty="n")
# This matches Figure 1 in Waller et al. 2007
### Now to fit Poisson GWR!
# The function 'ggwr' in the 'spgwr' package uses syntax similar to 'glm'
# (like we would use in a standard Poisson regression).
# 'longlat' tells the function that our coordinates are in longitude and
# latitude coordinates.
# 'ggwr.sel' selects the bandwidth for GWR based on the data, the model,
# and cross-validation
houston.bw = ggwr.sel(violence ~ Z.log.total + Z.log.drug + offset(log(pop2000)),
data = houston,
#coords,
adapt = FALSE,
gweight = gwr.Gauss,
family = poisson,
verbose = TRUE,
longlat = TRUE,
RMSE=FALSE,
tol=.Machine$double.eps^0.25)
knitr::opts_chunk$set(echo = TRUE)
##Load libraries
library(spdep)
library(INLA)
# Set my working directory (Lance's here for example)
#setwd("~/OneDrive - Emory University/meetings/SISMID.2021/SISMID.2021.Waller.Rcode")
# Read in data (included in the 'foreign' library.)
library(foreign)
nydata <- read.dbf(system.file("etc/misc/nydata.dbf", package="spdep")[1])
# Format data for INLA
coordinates(nydata) <- c("X", "Y")
nyadjmat <- as.matrix(read.dbf(system.file("etc/misc/nyadjwts.dbf",
package="spdep")[1])[-1])
ID <- as.character(names(read.dbf(system.file("etc/misc/nyadjwts.dbf",
package="spdep")[1]))[-1])
identical(substring(ID, 2, 10), substring(as.character(nydata$AREAKEY), 2, 10))
nyadjlw <- mat2listw(nyadjmat, as.character(nydata$AREAKEY))
listw_NY <- nb2listw(nyadjlw$neighbours, style="B")
##Load libraries
library(spdep)
library(INLA)
# Set my working directory (Lance's here for example)
#setwd("~/OneDrive - Emory University/meetings/SISMID.2021/SISMID.2021.Waller.Rcode")
# Read in data (included in the 'foreign' library.)
library(foreign)
nydata <- read.dbf(system.file("etc/misc/nydata.dbf", package="spdep")[1])
# Format data for INLA
coordinates(nydata) <- c("X", "Y")
nyadjmat <- as.matrix(read.dbf(system.file("etc/misc/nyadjwts.dbf",
package="spdep")[1])[-1])
ID <- as.character(names(read.dbf(system.file("etc/misc/nyadjwts.dbf",
package="spdep")[1]))[-1])
identical(substring(ID, 2, 10), substring(as.character(nydata$AREAKEY), 2, 10))
nyadjlw <- mat2listw(nyadjmat, as.character(nydata$AREAKEY))
listw_NY <- nb2listw(nyadjlw$neighbours, style="B")
# Calculate overall rate
rate <- sum(nydata$TRACTCAS) / sum(nydata$POP8)
# Set expected number of cases (population * rate)
Expected <- nydata$POP8 * rate
# Calculate standardized mortality ratio (SMR)
SMR <- nydata$TRACTCAS / nydata$Expected
nydata$POP8
rate
# Calculate overall rate
rate <- sum(nydata$TRACTCAS) / sum(nydata$POP8)
# Set expected number of cases (population * rate)
Expected <- nydata$POP8 * rate
# Calculate standardized mortality ratio (SMR)
SMR <- nydata$TRACTCAS / nydata$Expected
# Fit ICAR model
# Assuming here that the order of nydata and nyadjmat are the same
ID_new <- seq(nrow(nydata)) # I think INLA needs the IDs to be 1:n
nydata$ID_new <- ID_new
nyadjlw <- mat2listw(nyadjmat, row.names = ID_new)
listw_NY <- nb2listw(nyadjlw$neighbours, style="B")
# FEED THE FOLLOWING INTO INLA'S graph ARGUMENT instead of listw_NY
nyadj_matrix <- as(nb2mat(nyadjlw$neighbours, style = "B"), "Matrix")
m.icar <- inla(trunc(TRACTCAS) ~ 1 + PCTAGE65P + AVGIDIST + PCTOWNHOME +
f(ID_new, model = "besag", graph = nyadj_matrix),
data = as.data.frame(nydata), E = Expected, family ="poisson",
control.predictor = list(compute = TRUE),
control.compute = list(dic = TRUE, waic = TRUE))
summary(m.icar)
install.packages("surveillance", lib="/Library/Frameworks/R.framework/Versions/4.2/Resources/library")
knitr::opts_chunk$set(echo = TRUE)
# Set my working directory (Lance's here for example)
setwd("~/Downloads")
myrtles.healthy = scan("myrtles.healthy.d",list(x=0,y=0))
getwd()
# Set my working directory (Lance's here for example)
setwd("~/Downloads")
myrtles.healthy = scan("myrtles.healthy.d",list(x=0,y=0))
knitr::opts_chunk$set(echo = FALSE)
# Set my working directory (Lance's here for example)
setwd("~/Downloads")
myrtles.healthy = scan("myrtles.healthy.d",list(x=0,y=0))
# Set my working directory (Lance's here for example)
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/myrtles.healthy.d")
# Set my working directory (Lance's here for example)
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/myrtles.healthy.d",destfile = "~/myrtles.healthy.d")
myrtles.healthy = scan("myrtles.healthy.d",list(x=0,y=0))
#####################################
# Let's see what we have.  Typing the
# name "myrtles.healthy" and hitting return
# prints out the values.
#####################################
# Commented out so it doesn't list everything in the handout
#myrtles.healthy
####################################
# The "names" command just give the
# names of the variables inside the data frame.
####################################
names(myrtles.healthy)
###################################
# To access the value within a data frame
# type the name of the frame, a dollar sign,
# then the name of the variable.
#####################################
#Commented out so it doesn't list every value in the handout
#myrtles.healthy$x
####################################
# To find out how many observations are
# in myrtles.healty$x, use the "length"
# command.
####################################
length(myrtles.healthy$x)
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/myrtles.d",destfile = "~/myrtles.d")
myrtles.all = scan("myrtles.d",list(x=0,y=0))
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/myrtles.diseased.d",destfile = "~/myrtles.diseased.d")
myrtles.diseased = scan("myrtles.diseased.d",list(x=0,y=0))
#####################################
# Let's plot the data
#####################################
plot(myrtles.healthy$x, myrtles.healthy$y)
#####################################
# The "points" command adds points to a plot,
# and the "pch" option changes the "plot character".
# Let's add the diseased myrtle locations and plot
# them as "D"s.
#####################################
points(myrtles.diseased$x,myrtles.diseased$y,pch="D")
#####################################
# Notice that the plot is sort of square, but
# that the range of values for x is different
# from that for y.  Let's set the limits
# so that they are the same.  First, we find
# min and max of the x and y coordinates for
# ALL myrtle locations (healthy and diseased).
#####################################
min(myrtles.all$x)
max(myrtles.all$x)
min(myrtles.all$y)
max(myrtles.all$y)
#####################################
# We can also use the "range" command
# to do this.
#####################################
range(myrtles.all$x)
range(myrtles.all$y)
#####################################
# Looks like if we set the plot boundaries
# for (0,215) for x and y, we'll catch all
# of the points.  We use the "xlim" and
# "ylim" parameters in the plot command.
# NOTE: we can continue a command onto the next
# line if we end with a comma and don't include
# a closing paranthesis until we are ready.
# ALSO NOTE: "c(0,215)" concatenates the values
# 0 and 215 into a vector.
#####################################
plot(myrtles.healthy$x,myrtles.healthy$y,xlim=c(0,215),
ylim=c(0,215))
###################################
# Finally, to make sure R draws the plotting area
# as a square, we introduce the "par" command.
# "par" sets plotting parameters and is a very,
# very, very, very, very, very, very important
# command with lots of uses.  You have to set
# "par" before plotting, but the settings stay until
# the next "par" command resets them.
# "pty" = "plot type" and "pty=s" means "set plot type
# to square".
####################################
par(pty="s")
plot(myrtles.healthy$x,myrtles.healthy$y,xlim=c(0,215),
ylim=c(0,215))
####################################
# We can also use "par" to put put multiple plots
# in the same window.
# "mfrow" means "multiple figures by row".
# "mfrow=c(1,2)"  means "multiple figures, one row
# containing two figures".  Let's try it.
####################################
par(pty="s",mfrow=c(1,2))
plot(myrtles.healthy$x,myrtles.healthy$y,xlim=c(0,215),
ylim=c(0,215))
title("Healthy")
plot(myrtles.diseased$x,myrtles.diseased$y,xlim=c(0,215),
ylim=c(0,215))
title("Diseased")
knitr::opts_chunk$set(echo = TRUE)
##################################
# CSR, edge-corrected within polygon
##################################
dists <- 1:300
dists <- dists*20
nsim <- 500
Kmat <- matrix(0,nsim,length(dists))
Kmat.cas <- matrix(0,nsim,length(dists))
Kmat.con <- matrix(0,nsim,length(dists))
# Need mypoly to be a matrix)
mypoly.mat = cbind(mypoly$x,mypoly$y)
mypoly$x
######################
# Open libraries
######################
library(splancs)
######################
# Set path to data sets, etc.
######################
# Set my working directory (Lance's here for example)
#setwd("~/OneDrive - Emory University/meetings/SISMID.2021/SISMID.2021.Waller.Rcode")
# Read in data with south region removed
dental <- scan("dental.reduced.dat",list(lab=0,aff=0,x=0,y=0))
# read in previously defined polygon boundary
mypoly <- read.table("mypoly.dat")
mypoly$x
View(mypoly)
mypoly$X1
####################################
# K function analysis comparing to CSR within a polygon.
# Using splancs functions
####################################
dental.p <- as.points(dental$x,dental$y)
dentcas.p <- as.points(dental$x[dental$aff==1],dental$y[dental$aff==1])
dentcon.p <- as.points(dental$x[dental$aff==0],dental$y[dental$aff==0])
#####
# Plot points to see data set
#####
par(pty="s")
# dental$y has a bigger range so this tries to add half of the
# extra to each side
extra <- ( diff(range(dental$y))-diff(range(dental$x)) )/2
plot(dental.p,pch="*",xlim=c(min(dental$x)-extra,max(dental$x)+extra),
ylim=range(dental$y),
xlab="Easting",ylab="Northing")
title("Grave locations (*=grave, O=affected)")
points(dentcas.p,pch="O")
## Interactively define polygon
#mypoly <- getpoly()
##save this polygon
#write.table(mypoly,paste(path,"mypoly.dat",sep=""))
polygon(mypoly)
# Add arrows to double locations
arrows(5305,6000,5305,5600,code=1,length=0.1)
arrows(10200,5222,10800,5222,code=1,length=0.1)
install.packages("variosig", lib="/Library/Frameworks/R.framework/Versions/4.2/Resources/library")
install.packages("ggpubr", lib="/Library/Frameworks/R.framework/Versions/4.2/Resources/library")
install.packages("latticeExtra", lib="/Library/Frameworks/R.framework/Versions/4.2/Resources/library")
install.packages("fields", lib="/Library/Frameworks/R.framework/Versions/4.2/Resources/library")
install.packages("mapproj", lib="/Library/Frameworks/R.framework/Versions/4.2/Resources/library")
library(knitr)
opts_chunk$set(collapse=TRUE, fig.align='center', tidy=TRUE, tidy.opts=list(blank=TRUE, width.cutoff=70,strip.white=TRUE), warning=FALSE,message=FALSE,cache=T)
# Install necessary packages
library(tidyverse)
# install.packages("INLA",repos=c(getOption("repos"),
# INLA="https://inla.r-inla-download.org/R/testing"), dep=TRUE)
library(INLA)
# devtools::install_github("richardli/SUMMER", build_vignettes = F, force = T)
library(SUMMER)
library(rgdal)
library(spdep)
library(mapproj)
library(ggpubr)
# read in direct estimates and shape files
# must have a folder named R-examples in your current working directory
if (!("R-examples" %in% list.files())) {
dir.create("R-examples")
}
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/direct.csv",
destfile = "R-examples/direct.csv")
direct_df <- read.csv("R-examples/direct.csv")
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/gadm36_MWI_1.shx",
destfile = "R-examples/gadm36_MWI_1.shx")
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/gadm36_MWI_1.shp",
destfile = "R-examples/gadm36_MWI_1.shp")
download.file("http://faculty.washington.edu/jonno/SISMIDmaterial/gadm36_MWI_1.dbf",
destfile = "R-examples/gadm36_MWI_1.dbf")
geo <- rgdal::readOGR("R-examples",
layer = "gadm36_MWI_1", verbose=F)
# filter out Likoma
geo <- geo[geo$NAME_1 != "Likoma",]
# Make lowercase to match DHS data
geo$NAME_1 <- geo$NAME_1 %>% str_to_lower() %>% factor()
geo@data$id <- rownames(geo@data)
#create neighbor matrix
nb.r <- poly2nb(geo, queen = F, row.names = geo$NAME_1)
mat <- nb2mat(nb.r, style = "B", zero.policy = TRUE)
colnames(mat) <- rownames(mat)
mapPlot(direct_df, variables = "p", geo = geo, by.data = "region",
by.geo = "NAME_1", legend.label = "Prevalence",
removetab = TRUE)
if (!require(gpclib)) install.packages("gpclib", type="source")
gpclibPermit()
gpclibPermitStatus()
library(maptools)
gpclibPermit()
mapPlot(direct_df, variables = "p", geo = geo, by.data = "region",
by.geo = "NAME_1", legend.label = "Prevalence",
removetab = TRUE)
gpclibPermit()
View(contact_all)
contact_all["USA"]
us_all = contact_all["USA"]
us_all = unlist(contact_all["USA"])
us_all
us_all = contact_all["USA"]
us_all
us_all[1]
us_all = contact_all["USA"][1]
us_all = contact_all["USA"]$USA
write.csv(us_all,file='test.csv', row.names=FALSE)
write.csv(us_all,file='/erinstafford/Desktop/contacts_all_USA.csv', row.names=FALSE)
write.csv(us_all,file='~/Desktop/contacts_all_USA.csv', row.names=FALSE)
write.csv(us_all,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_all_USA.csv', row.names=FALSE,col.names=FALSE)
load("/Users/erinstafford/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contact_home.rdata")
load("/Users/erinstafford/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contact_others.rdata")
load("/Users/erinstafford/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contact_school.rdata")
load("/Users/erinstafford/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contact_work.rdata")
write.csv(us_school,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_school_USA.csv')
us_all = contact_all["USA"]$USA
write.csv(us_all,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_all_USA.csv')
us_work = contact_work["USA"]$USA
write.csv(us_work,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_work_USA.csv')
us_home = contact_home["USA"]$USA
write.csv(us_home,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_home_USA.csv')
us_school = contact_school["USA"]$USA
write.csv(us_school,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_school_USA.csv')
us_other = contact_others["USA"]$USA
write.csv(us_other,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_other_USA.csv')
us_all = contact_all["USA"]$USA
write.csv(us_all,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_all_USA.csv', row.names=FALSE)
us_work = contact_work["USA"]$USA
write.csv(us_work,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_work_USA.csv', row.names=FALSE)
us_home = contact_home["USA"]$USA
write.csv(us_home,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_home_USA.csv', row.names=FALSE)
us_school = contact_school["USA"]$USA
write.csv(us_school,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_school_USA.csv', row.names=FALSE)
us_other = contact_others["USA"]$USA
write.csv(us_other,file='~/Desktop/updated_COVID_19_Project/contact_matrices_177_countries/contacts_other_USA.csv', row.names=FALSE)
o	download.file(url="https://zenodo.org/records/3986872/files/GLCFCS30_E100N15.tif?download=1",destfile="C:\\Users\\vi1570\\Desktop\\Current_desktop\\PANDASIA\\GLCFCS30_E100N15.tif")
setwd("~/Documents/Github/Bat_model")
library(raster)
thai_data =raster("GLCFCS30_E100N15.tif")
legend <- read.csv(text="Value,Label,Red,Green,Blue
10,	Rainfed cropland,	255,255,100
11,	Herbaceous cover,	255,255,100
12,	Tree or shrub cover (Orchard),	255,255,0
20,	Irrigated cropland,	170,240,240
50,	Evergreen broadleaved forest,	0,100,0
60,	Deciduous broadleaved forest,	0,160,0
61,	Open deciduous broadleaved forest (0.15<fc<0.4),	0,160,0
62,	Closed deciduous broadleaved forest (fc>0.4),	170,200,0
70,	Evergreen needle-leaved forest,	0,60,0
71,	Open evergreen needle-leaved forest (0.15< fc <0.4),	0,60,0
72,	Closed evergreen needle-leaved forest (fc >0.4),	0,80,0
80,	Deciduous needle-leaved forest,	40,80,0
81,	Open deciduous needle-leaved forest (0.15< fc <0.4),	40,80,0
82,	Closed deciduous needle-leaved forest (fc >0.4),	40,100,0
90,	Mixed leaf forest (broadleaved and needle-leaved),	20,130,0
120,	Shrubland,	150,100,0
121, Evergreen shrubland,	150,75,0
122,	Deciduous shrubland,	150,100,0
130,	Grassland,	255,180,50
140,	Lichens and mosses,	255,220,210
150,	Sparse vegetation (fc<0.15),	255,235,175
152,	Sparse shrubland (fc<0.15),	255,210,120
153,	Sparse herbaceous (fc<0.15),	255,235,175
180,	Wetlands,	0,220,130
190,	Impervious,	195,20,0
200,	Bare areas,	255,245,215
201,	Consolidated bare areas,	220,220,220
202,	Unconsolidated bare areas,	255,245,215
210,	Water body,	0,70,200
220,	Permanent ice and snow,	255,255,255
250,	Filled value,	255,255,255")
legend$col <-  rgb(legend$Red, legend$Green, legend$Blue, maxColorValue=255)
tb <- legend[, c('Value', 'Label')]
colnames(tb)[1] = "ID"
tb$Label <- substr(tb$Label, 1,10)
levels(thai_data) <- tb
library(rasterVis)
w10 <- thai_data[6700:8700,8000:10000, drop=FALSE]
levelplot(w10, col.regions=legend$col)
writeRaster(w10,'test.tif',options=c('TFW=YES'))
writeRaster(w10,'test.tif',options=c('TFW=YES'),overwrite=TRUE)
